from bs4 import BeautifulSoup
import pandas as pd
import re
import time
from typing import Optional, Dict
from src.exceptions import ParseError, SaveToExcelError
import logging

logger = logging.getLogger(__name__)

def cvss_edited(cvss):
    try:
        pattern = r'\d+(?:.\d+)?'
        number = re.findall(pattern, cvss)
        if float(number[0]) < 4:
            return f'{number[0]} Low'
        elif float(number[0]) < 7:
            return f'{number[0]} Medium'
        elif float(number[0]) < 9:
            return f'{number[0]} High'
        else:
            return f'{number[0]} Critical'
    except Exception:
        return 'N/A'

def find_main_table_with_retry(soup, max_attempts=2, delay=5):
    """Поиск основной таблицы с повторной попыткой"""
    for attempt in range(max_attempts):
        main_table = soup.find('table', class_='table')
        if main_table:
            return main_table
        
        if attempt < max_attempts - 1:
            logger.debug(f"Table not found, retrying in {delay} seconds... (attempt {attempt + 1})")
            time.sleep(delay)
    
    logger.warning('Main table not found after %d attempts. Setting stop flag.', max_attempts)
    return None

class VulnerabilityParser:
    def parse_vulnerability_data(self, html: str, url: str) -> pd.DataFrame:
        try:
            soup = BeautifulSoup(html, 'html.parser')
            data = self._extract_data(soup, url)
            
            if data is None:
                return pd.DataFrame([{'should_stop': True}])
            
            return pd.DataFrame([data])
            
        except Exception as e:
            logger.error(f'Parsing failed: {str(e)}')
            return pd.DataFrame([{'should_stop': True}])

    def _extract_data(self, soup: BeautifulSoup, url: str) -> Optional[Dict[str, str]]:
        data = {
            'Вендор': 'N/A',
            'Продукт': 'N/A',
            'CVSS': 'N/A',
            'CVE': 'N/A',
            'URL': url,
            'should_stop': False
        }

        main_table = find_main_table_with_retry(soup)
        if not main_table:
            data['should_stop'] = True
            return data

        # Парсим информацию об уязвимом ПО
        for row in main_table.find_all('tr'):
            cells = row.find_all('td')
            if len(cells) < 4:
                continue

            if len(cells) > 0:
                matches = re.findall(r'<span>([^<]+?)</span>', str(cells[0]))
                if matches:
                    data['Вендор'] = matches[0]

            if len(cells) > 1:
                matches = re.findall(r'<span>([^<]+?)</span>', str(cells[1]))
                if matches:
                    data['Продукт'] = matches[0]

        # Парсим уровень опасности (CVSS)
        for row in main_table.find_all('tr'):
            cells = row.find_all('td')
            if len(cells) < 2:
                continue

            value = cells[1].get_text(strip=True)
            cvss_match = re.search(r'CVSS 3\.0 составляет (\d+,\d+)', value)
            if cvss_match:
                cvss_value_with_comma = cvss_match.group(1)
                cvss_value_with_dot = cvss_value_with_comma.replace(',', '.')
                data['CVSS'] = cvss_edited(cvss_value_with_dot)

        # Парсим CVE идентификаторы
        for row in main_table.find_all('tr'):
            cells = row.find_all('td')
            if len(cells) < 2:
                continue

            header = cells[0].get_text(strip=True).lower()
            value = cells[1].get_text(strip=True)

            if 'идентификаторы других систем описаний уязвимостей' in header:
                cve_matches = re.findall(r'CVE-\d{4}-\d{4,}', value)
                if cve_matches:
                    data['CVE'] = ', '.join(cve_matches)

        if all(value == 'N/A' for key, value in data.items() if key not in ['URL', 'should_stop']):
            logger.warning("All values are 'N/A', setting stop flag.")
            data['should_stop'] = True

        return data

    def save_to_excel(self, df: pd.DataFrame, output_file: str) -> None:
        try:
            if not df.empty:
                df.to_excel(output_file, index=False)
        except Exception as e:
            raise SaveToExcelError(f'Failed to save to Excel: {str(e)}')
